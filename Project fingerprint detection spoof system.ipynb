{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39872115",
   "metadata": {},
   "source": [
    "# Fingerprint Spoof Detection System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391bde01",
   "metadata": {},
   "source": [
    "This task involved building a fingerprint spoof detection system that would help differentiate and detect a real and a fake fingerprint. With the help of open-source computer vision (OpenCV), local binary pattern (LBP), and support vector machine (SVM) among other Python modules. The system was successfully developed to identify and recognize fake and authentic fingerprints from a biometric system. The dataset used for this task was provided by the instructor. There were four datasets provided: real and fake training datasets, real and fake testing datasets. On successful development of the system, the model was able to differentiate between an authentic and a spoof fingerprint with an accuracy of 84.17%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b255ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import feature\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3476b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing training and testing variables as open lists\n",
    "\n",
    "X_train = [] #Independent variable for real and fake train data\n",
    "y_train= []  # Dependent variable for real and fake train data\n",
    "\n",
    "\n",
    "X_test = []  # Independent variable for real and fake test data\n",
    "y_test = []  # Dependent variable for real and fake test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3596d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory\n",
    "path = os.chdir('D:\\\\Python\\\\Datafolder\\\\Fingerprint')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae35313a",
   "metadata": {},
   "source": [
    "### Extracting Local Binary Pattern Histogram (LBPH) features from real training fingerprint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93fb7520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting LBPH features from real training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:23<00:00,  8.63it/s]\n"
     ]
    }
   ],
   "source": [
    "#Importing data\n",
    "realfgprint_data = os.listdir('TrainLive')   #sorted(os.listdir('TrainLive'))\n",
    "print ('Extracting LBPH features from real training data')\n",
    "for image in tqdm(realfgprint_data):\n",
    "    img = cv2.imread(os.path.join('TrainLive',image))\n",
    "    \n",
    "    # Resizing the images\n",
    "    cv2.resize(img,(100,100))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    # Using Local Binary Pattern (LBP) for texture classification and getting histogram\n",
    "    local_binary = feature.local_binary_pattern(img, 22, 6, method='uniform')\n",
    "    histo, bins = np.histogram(local_binary.ravel(), bins=np.arange(0,26), range=(0,10))\n",
    "\n",
    "    # standardizing the histogram\n",
    "    histo = histo.astype('float')\n",
    "    histo /= (histo.sum() + 1e-5)\n",
    "        \n",
    "    # Appending the image values to the dependent and independent variables\n",
    "    y_train.append(1) \n",
    "    X_train.append(histo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751fbfa1",
   "metadata": {},
   "source": [
    "### Extracting LBPH features from fake fingerprint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62633b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting LBPH features from fake training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:22<00:00,  8.73it/s]\n"
     ]
    }
   ],
   "source": [
    "fakefgprint_data = os.listdir('TrainSpoof')   #sorted(os.listdir('TrainSpoof'))\n",
    "print ('Extracting LBPH features from fake training data')\n",
    "for image in tqdm(fakefgprint_data):\n",
    "    img1 = cv2.imread(os.path.join('TrainSpoof',image))\n",
    "    cv2.resize(img1,(100,100))\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)  \n",
    "    \n",
    "    # Using LBP for texture classification and getting histogram\n",
    "    local_binary = feature.local_binary_pattern(img1, 22, 6, method='uniform')\n",
    "    hist, bins = np.histogram(local_binary.ravel(), bins=np.arange(0,26), range=(0,10))\n",
    "\n",
    "    # normalize the histogram\n",
    "    histo = histo.astype('float')\n",
    "    histo /= (histo.sum() + 1e-5)\n",
    "        \n",
    "    # Appending the image values to the dependent and independent variables\n",
    "    y_train.append(0) \n",
    "    X_train.append(histo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db3b635",
   "metadata": {},
   "source": [
    "### Extracting LBPH features from real testing fingerprint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9376edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting LBPH features from real testing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:23<00:00,  8.33it/s]\n"
     ]
    }
   ],
   "source": [
    "testfgprint_data = os.listdir('TestLive')  #sorted(os.listdir('TestLive'))\n",
    "print ('Extracting LBPH features from real testing data')\n",
    "for image in tqdm(testfgprint_data):\n",
    "    img2 = cv2.imread(os.path.join('TestLive',image))\n",
    "    cv2.resize(img2,(100,100))\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Using LBP for texture classification and getting histogram\n",
    "    local_binary = feature.local_binary_pattern(img2, 22, 6, method='uniform')\n",
    "    hist, bins = np.histogram(local_binary.ravel(), bins=np.arange(0,26), range=(0,10))\n",
    "\n",
    "    # normalize the histogram\n",
    "    histo = histo.astype('float')\n",
    "    histo /= (histo.sum() + 1e-5)\n",
    "        \n",
    "    # Appending the image values to the dependent and independent variables\n",
    "    y_test.append(1) \n",
    "    X_test.append(histo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e238b0",
   "metadata": {},
   "source": [
    "### Extracting LBPH features from spoof testing fingerprint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc76997d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting LBPH features from fake testing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:23<00:00,  8.58it/s]\n"
     ]
    }
   ],
   "source": [
    "faketest_data = os.listdir('TestSpoof')   #sorted(os.listdir('TestSpoof'))\n",
    "print ('Extracting LBPH features from fake testing data')\n",
    "for image in tqdm(faketest_data):\n",
    "    img3 = cv2.imread(os.path.join('TestSpoof',image))\n",
    "    cv2.resize(img3,(100,100))\n",
    "    img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Using LBP for texture classification and getting histogram\n",
    "    local_binary = feature.local_binary_pattern(img3, 22, 6, method='uniform')\n",
    "    hist, bins = np.histogram(local_binary.ravel(), bins=np.arange(0,26), range=(0,10))\n",
    "\n",
    "    # normalize the histogram\n",
    "    histo = histo.astype('float')\n",
    "    histo /= (histo.sum() + 1e-5)\n",
    "        \n",
    "    # Appending the image values to the dependent and independent variables\n",
    "    y_test.append(0) \n",
    "    X_test.append(histo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfa06797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling the data\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_test, y_test = shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c64e3145",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train \n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "771c1192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting it into training and testing data \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5f4547",
   "metadata": {},
   "source": [
    "## Training SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7eefd9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#Fitting the model\n",
    "svm_model = LinearSVC()\n",
    "svm_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21b78b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict\n",
    "y_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01acc5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of the SVM: 0.891\n",
      "Recall of the SVM: 1.0\n",
      "Accuracy of the SVM: 0.942\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "con_matrix = confusion_matrix(y_test,y_pred) #,labels=[\"Live\",\"Fake\"])\n",
    "TP = con_matrix[0][0]\n",
    "FN = con_matrix[0][1]\n",
    "FP = con_matrix[1][0]\n",
    "TN = con_matrix[1][1]\n",
    "\n",
    "print('Precision of the SVM:', round((TP / (TP+FP)),3))\n",
    "print('Recall of the SVM:', round((TP / (TP+FN)),3))\n",
    "print('Accuracy of the SVM:', round(((TP + TN) / (TP + TN + FP + FN)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c94d159c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058333333333333334"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for the error of prediction\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b7376774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57,  0],\n",
       "       [ 7, 56]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "53a125ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        57\n",
      "           1       1.00      0.89      0.94        63\n",
      "\n",
      "    accuracy                           0.94       120\n",
      "   macro avg       0.95      0.94      0.94       120\n",
      "weighted avg       0.95      0.94      0.94       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating reports\n",
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0e81d7",
   "metadata": {},
   "source": [
    "## THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
